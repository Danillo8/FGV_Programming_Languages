{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "ArgumentError: PyPlot not found in path",
     "output_type": "error",
     "traceback": [
      "ArgumentError: PyPlot not found in path",
      ""
     ]
    }
   ],
   "source": [
    "\n",
    "using PyPlot\n",
    "# -------------------------------------------------------------\n",
    "# this function allows us to generate random data where we want\n",
    "# -------------------------------------------------------------\n",
    "function generate_rnd(d,a,b)\n",
    "    p = rand(d)\n",
    "    r = zeros(d)\n",
    "    for i=1:d\n",
    "        r[i] = p[i]*(b-a) + a\n",
    "    end\n",
    "    return r\n",
    "end\n",
    "# ---------------------------\n",
    "# Decide what function to use\n",
    "# ---------------------------\n",
    "function f(x)\n",
    "    return sum([v^2 for v in x])\n",
    "end\n",
    "# ------------------------\n",
    "# Functions that will help\n",
    "# ------------------------\n",
    "function distance(v1,v2)\n",
    "    d = 0\n",
    "    for i=1:length(v1)\n",
    "        d += (v1[i]-v2[i])^2\n",
    "    end\n",
    "    return d^0.5\n",
    "end\n",
    "\n",
    "function relative_diference(a,b)\n",
    "    return abs((a-b)/b - 1)\n",
    "end\n",
    "\n",
    "function k_closest_neighbors(neighbors,point,k)\n",
    "    ns = [[distance(neighbors[j],point), neighbors[j]] for j=1:length(neighbors) if neighbors[j] != point]\n",
    "    if length(ns) == 0\n",
    "        return \"Empty neighborhood!\"\n",
    "    end\n",
    "    sort!(ns)\n",
    "    js = [ns[i][2] for i=1:k-1]\n",
    "    return js\n",
    "end\n",
    "\n",
    "function closest_neighbor_correted(p,S,U,k,threshold)\n",
    "    neighbors = [k for k in keys(S)]\n",
    "    for n in k_closest_neighbors(neighbors,p,length(neighbors)-1)\n",
    "        println(n, \"   \", relative_diference(g(n,U,k),g(n,S,k)))\n",
    "        if relative_diference(g(n,U,k),g(n,S,k)) <= threshold\n",
    "            return n\n",
    "        end\n",
    "    end\n",
    "    return Nothing\n",
    "end\n",
    "\n",
    "function g(x,S,k)\n",
    "    neighbors = [p for p in keys(S)]\n",
    "    gsum = sum([S[i] for i in k_closest_neighbors(neighbors,x,k)])\n",
    "    return gsum/k\n",
    "end\n",
    "# ---------------\n",
    "# Condense S to U\n",
    "# ---------------\n",
    "function condensate(S,k,threshold)\n",
    "    U = Dict()\n",
    "    neighbors = [k for k in keys(S)]\n",
    "    for i=1:k\n",
    "        p = neighbors[i]\n",
    "        U[p] = S[p]\n",
    "    end\n",
    "    t = true\n",
    "    while t\n",
    "        nt = 0\n",
    "        for p in [k for k in keys(S) if get(U,k,false) == false]\n",
    "            # Teste se o ponto está mal \"classificado\"\n",
    "            if relative_diference(g(p,U,k), g(p,S,k)) > threshold\n",
    "                # Buscar o vizinho bem \"classificado\" mais próximo\n",
    "                q = closest_neighbor_correted(p,S,U,k,threshold)\n",
    "                if q != Nothing\n",
    "                    U[q] = S[q]\n",
    "                    nt += 1\n",
    "                    #break\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        println(nt,t)\n",
    "        if nt == 0\n",
    "            t = false\n",
    "        end\n",
    "    end\n",
    "    return U\n",
    "end\n",
    "# --------------------------------------------\n",
    "# Defining parameters\n",
    "# --------------------------------------------\n",
    "N = 1000\n",
    "d = 2\n",
    "a,b = -5,5\n",
    "number_of_tests = 10\n",
    "k = 4\n",
    "want_to_condensate = false\n",
    "# To classification functions only\n",
    "L = 10\n",
    "# --------------------------------\n",
    "# Generating some data\n",
    "# --------------------------------\n",
    "x = [generate_rnd(d,a,b) for i=1:number_of_tests]\n",
    "data = [generate_rnd(d,a,b) for n=1:N]\n",
    "# --------------------------\n",
    "# Saving values for our data\n",
    "# --------------------------\n",
    "S = Dict()\n",
    "for n=1:N\n",
    "    S[data[n]] = f(data[n])\n",
    "end\n",
    "if want_to_condensate == true\n",
    "    U = condensate(S,k)\n",
    "else\n",
    "    U = S\n",
    "end\n",
    "# ------------------------------------\n",
    "# Print data when d = 1 and regression\n",
    "# ------------------------------------\n",
    "if d == 1\n",
    "    PyPlot.clf()\n",
    "    title(\"1d-k-NN-Regression\")\n",
    "    PyPlot.scatter([y[1] for y in x], [g(y,U,k) for y in x], color=\"red\")\n",
    "    PyPlot.scatter([p for p in keys(U)], [U[p] for p in keys(U)], color=\"blue\")\n",
    "    l1 = -1:0.1:1\n",
    "    l2 = f.(l1)\n",
    "    PyPlot.plot(l1,l2)\n",
    "    xlim((a,b))\n",
    "    if f([a]) == f([b])\n",
    "        ylim((-1,f([a])))\n",
    "    else\n",
    "        ylim((f([a]),f([b])))\n",
    "    end\n",
    "    PyPlot.savefig(\"D:\\\\Personal\\\\EMAp\\\\Machine Learning\\\\7-kNN\\\\1d-k-NN-Regression.pdf\")\n",
    "end\n",
    "# ------------------------------------------------------------------------------------\n",
    "# Print data divided (only makes sense with d = 2 and f with breakpoint = L)\n",
    "# ------------------------------------------------------------------------------------\n",
    "if d == 2\n",
    "    title(\"2d-k-NN-Classification-by-Regression\")\n",
    "    PyPlot.clf()\n",
    "    for y in x\n",
    "        if g(y,U,k) >= L\n",
    "            color = \"purple\"\n",
    "        else\n",
    "            color = \"pink\"\n",
    "        end\n",
    "        PyPlot.scatter([y[1]],[y[2]],color=color,s = 50)\n",
    "    end\n",
    "    neighbors = [p for p in keys(U)]\n",
    "    PyPlot.scatter([x[1] for x in neighbors if U[x] >= L],[x[2] for x in neighbors if U[x] >= L],color=\"blue\", label = \"Positivo\", s = 40)\n",
    "    PyPlot.scatter([x[1] for x in neighbors if U[x] < L],[x[2] for x in neighbors if U[x] < L],color=\"red\", label = \"Negativo\", s = 40)\n",
    "    xlim((a,b))\n",
    "    ylim((a,b))\n",
    "    PyPlot.savefig(\"D:\\\\Personal\\\\EMAp\\\\Machine Learning\\\\7-kNN\\\\2d-k-NN-Regression.pdf\")\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generate_rnd (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function generate_rnd(d,a,b)\n",
    "    p = rand(d)\n",
    "    r = zeros(d)\n",
    "    for i=1:d\n",
    "        r[i] = p[i]*(b-a) + a\n",
    "    end\n",
    "    return r\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 5.41659\n",
       " 5.85069\n",
       " 5.68311\n",
       " 5.01189"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_rnd(4,5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.5",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
